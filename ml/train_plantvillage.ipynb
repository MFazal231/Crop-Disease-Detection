{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working dir: c:\\Users\\np792\\Downloads\\crop-disease-detector\\crop-disease-detector\\ml\n"
     ]
    }
   ],
   "source": [
    "# PlantVillage Training Notebook\n",
    "# - Downloads dataset via kagglehub\n",
    "# - Trains a Keras CNN\n",
    "# - Exports TFJS model for frontend\n",
    "\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "print(\"Working dir:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Install deps (local env)\n",
    "%pip -q install kagglehub tensorflow tensorflowjs matplotlib scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\np792\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\np792\\.cache\\kagglehub\\datasets\\emmarex\\plantdisease\\versions\\1\n"
     ]
    }
   ],
   "source": [
    "# Download PlantVillage\n",
    "import kagglehub\n",
    "path = kagglehub.dataset_download(\"emmarex/plantdisease\")\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 33027 images belonging to 16 classes.\n",
      "Found 8249 images belonging to 16 classes.\n",
      "Classes: 16\n"
     ]
    }
   ],
   "source": [
    "# Prepare data generators\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "dataroot = pathlib.Path(path)\n",
    "img_size = (224, 224)\n",
    "batch_size = 32\n",
    "\n",
    "train_dir = dataroot / 'PlantVillage'\n",
    "if not train_dir.exists():\n",
    "    # Some archives expand differently; adjust here if needed\n",
    "    # Fallback to root\n",
    "    train_dir = dataroot\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2,\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    ")\n",
    "\n",
    "train_gen = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    subset='training',\n",
    "    class_mode='sparse'\n",
    ")\n",
    "val_gen = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    subset='validation',\n",
    "    class_mode='sparse'\n",
    ")\n",
    "\n",
    "class_names = list(train_gen.class_indices.keys())\n",
    "print('Classes:', len(class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ mobilenetv2_1.00_224            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">20,496</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ mobilenetv2_1.00_224            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1280\u001b[0m)     │     \u001b[38;5;34m2,257,984\u001b[0m │\n",
       "│ (\u001b[38;5;33mFunctional\u001b[0m)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │        \u001b[38;5;34m20,496\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,278,480</span> (8.69 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,278,480\u001b[0m (8.69 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,496</span> (80.06 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m20,496\u001b[0m (80.06 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> (8.61 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,257,984\u001b[0m (8.61 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build a simple CNN (or swap with Transfer Learning)\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "base = tf.keras.applications.MobileNetV2(\n",
    "    include_top=False, input_shape=(224,224,3), weights='imagenet')\n",
    "base.trainable = False\n",
    "\n",
    "model = models.Sequential([\n",
    "    base,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(len(class_names), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1032/1032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m804s\u001b[0m 775ms/step - accuracy: 0.5288 - loss: 1.1761 - val_accuracy: 0.2363 - val_loss: 2.7232\n",
      "Epoch 2/5\n",
      "\u001b[1m   1/1032\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8:21\u001b[0m 487ms/step - accuracy: 0.4062 - loss: 1.1029"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\np792\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\epoch_iterator.py:116: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1032/1032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 155ms/step - accuracy: 0.4062 - loss: 1.1029 - val_accuracy: 0.2265 - val_loss: 2.7042\n",
      "Epoch 3/5\n",
      "\u001b[1m1032/1032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m699s\u001b[0m 677ms/step - accuracy: 0.5471 - loss: 1.0076 - val_accuracy: 0.1818 - val_loss: 3.0320\n",
      "Epoch 4/5\n",
      "\u001b[1m1032/1032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 125ms/step - accuracy: 0.4688 - loss: 1.2264 - val_accuracy: 0.1773 - val_loss: 3.0185\n",
      "Epoch 5/5\n",
      "\u001b[1m1032/1032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m687s\u001b[0m 666ms/step - accuracy: 0.5463 - loss: 0.9851 - val_accuracy: 0.2419 - val_loss: 3.3721\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "steps = train_gen.samples // batch_size\n",
    "val_steps = val_gen.samples // batch_size\n",
    "\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    steps_per_epoch=steps,\n",
    "    validation_data=val_gen,\n",
    "    validation_steps=val_steps,\n",
    "    epochs=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model.h5\n",
      "\n",
      "Now run:\n",
      "tensorflowjs_converter --input_format=keras export_tfjs/model.h5 export_tfjs\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "import json\n",
    "\n",
    "out_dir = pathlib.Path('export_tfjs')\n",
    "out_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Save labels\n",
    "labels_json = out_dir / 'labels.json'\n",
    "with open(labels_json, 'w') as f:\n",
    "    json.dump(class_names, f)\n",
    "\n",
    "# Save as Keras format and convert\n",
    "model.save(out_dir / 'model.h5')\n",
    "\n",
    "print('Saved model.h5')\n",
    "print('\\nNow run:')\n",
    "print(f'tensorflowjs_converter --input_format=keras {out_dir.as_posix()}/model.h5 {out_dir.as_posix()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-hub==0.15.0\n",
      "  Downloading tensorflow_hub-0.15.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: numpy>=1.12.0 in c:\\users\\np792\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-hub==0.15.0) (2.0.2)\n",
      "Requirement already satisfied: protobuf>=3.19.6 in c:\\users\\np792\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-hub==0.15.0) (5.29.5)\n",
      "Downloading tensorflow_hub-0.15.0-py2.py3-none-any.whl (85 kB)\n",
      "Installing collected packages: tensorflow-hub\n",
      "  Attempting uninstall: tensorflow-hub\n",
      "    Found existing installation: tensorflow-hub 0.12.0\n",
      "    Uninstalling tensorflow-hub-0.12.0:\n",
      "      Successfully uninstalled tensorflow-hub-0.12.0\n",
      "Successfully installed tensorflow-hub-0.15.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflowjs 3.18.0 requires tensorflow-hub<0.13,>=0.7.0, but you have tensorflow-hub 0.15.0 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade tensorflow-hub==0.15.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting model...\n",
      "Error: 2025-11-04 04:57:17.822236: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-04 04:57:19.815287: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "C:\\Users\\np792\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflowjs\\read_weights.py:28: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  np.uint8, np.uint16, np.object, np.bool]\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\np792\\AppData\\Local\\Programs\\Python\\Python312\\Scripts\\tensorflowjs_converter.exe\\__main__.py\", line 4, in <module>\n",
      "  File \"C:\\Users\\np792\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflowjs\\__init__.py\", line 21, in <module>\n",
      "    from tensorflowjs import converters\n",
      "  File \"C:\\Users\\np792\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflowjs\\converters\\__init__.py\", line 21, in <module>\n",
      "    from tensorflowjs.converters.converter import convert\n",
      "  File \"C:\\Users\\np792\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflowjs\\converters\\converter.py\", line 35, in <module>\n",
      "    from tensorflowjs.converters import keras_h5_conversion as conversion\n",
      "  File \"C:\\Users\\np792\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflowjs\\converters\\keras_h5_conversion.py\", line 33, in <module>\n",
      "    from tensorflowjs import write_weights  # pylint: disable=import-error\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\np792\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflowjs\\write_weights.py\", line 25, in <module>\n",
      "    from tensorflowjs import read_weights\n",
      "  File \"C:\\Users\\np792\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflowjs\\read_weights.py\", line 28, in <module>\n",
      "    np.uint8, np.uint16, np.object, np.bool]\n",
      "                         ^^^^^^^^^\n",
      "  File \"C:\\Users\\np792\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\__init__.py\", line 408, in __getattr__\n",
      "    raise AttributeError(__former_attrs__[attr])\n",
      "AttributeError: module 'numpy' has no attribute 'object'.\n",
      "`np.object` was a deprecated alias for the builtin `object`. To avoid this error in existing code, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "The aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n",
      "    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations. Did you mean: 'object_'?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "import json\n",
    "import subprocess\n",
    "\n",
    "out_dir = pathlib.Path('export_tfjs')\n",
    "out_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Save labels\n",
    "with open(out_dir / 'labels.json', 'w') as f:\n",
    "    json.dump(class_names, f)\n",
    "\n",
    "# Save model\n",
    "model_path = out_dir / 'model.keras'\n",
    "model.save(model_path.as_posix())\n",
    "\n",
    "# Convert using subprocess\n",
    "print('Converting model...')\n",
    "result = subprocess.run([\n",
    "    'tensorflowjs_converter',\n",
    "    '--input_format=keras',\n",
    "    model_path.as_posix(),\n",
    "    out_dir.as_posix()\n",
    "], capture_output=True, text=True)\n",
    "\n",
    "if result.returncode == 0:\n",
    "    print('✓ Conversion successful!')\n",
    "    print(f'✓ Files saved to: {out_dir.resolve()}')\n",
    "else:\n",
    "    print('Error:', result.stderr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
